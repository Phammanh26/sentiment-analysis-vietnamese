{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP-kVnX7g-tR",
        "outputId": "ac53b470-5913-4945-8422-ae6b1dbf0be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /Users/phamvanmanh/opt/anaconda3/lib/python3.8/site-packages (3.6.1)\n",
            "Requirement already satisfied: tqdm in /Users/phamvanmanh/opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.59.0)\n",
            "Requirement already satisfied: click in /Users/phamvanmanh/opt/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex in /Users/phamvanmanh/opt/anaconda3/lib/python3.8/site-packages (from nltk) (2021.4.4)\n",
            "Requirement already satisfied: joblib in /Users/phamvanmanh/opt/anaconda3/lib/python3.8/site-packages (from nltk) (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1GQxoqsVL1vb"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from nltk.corpus import stopwords\n",
        "# import nltk\n",
        "import re\n",
        "# from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_special_character( word: str) -> str:\n",
        "        # add white space between normal word and special character.\n",
        "\n",
        "        tail_special = '\"\"''v@_!#$%^&*()<>?/\\|}{~:;[],.+-\\n'\n",
        "        head_special = '@_!#$%^&*()<>?/\\|}{~:;[],.+-'\n",
        "\n",
        "        for i in reversed(range(len(word))):\n",
        "            if word[i] not in tail_special:\n",
        "                break\n",
        "        \n",
        "        if i != len(word) - 1:\n",
        "            word = word[0: i + 1] + \" \" + word[i + 1:]\n",
        "       \n",
        "\n",
        "        for i in range(len(word)):\n",
        "            if word[i] not in head_special:\n",
        "                break\n",
        "          \n",
        "        if i != 0:\n",
        "            word = word[0: i] + \" \" + word[i:]            \n",
        "            return word\n",
        "        return word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(@ manh ].vvvv'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_special_character(\"(@manh].vvvv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'('"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\" @(manh)@gmail.com t√¥i c√≥ ·∫•t nhi·ªÅu (@manh)\"[34+1:35+1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28NKRXV9L1ve"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjOcUen4ZUsH"
      },
      "source": [
        "## Clean Data Funcion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK81qCA2ZUEw"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import string\n",
        "from pyvi import ViTokenizer, ViPosTagger\n",
        "\n",
        "def split_special_character(word: str, pos_head=True):\n",
        "    # add white space between normal word and special character.\n",
        "\n",
        "    tail_special = '\"\"''v@_!#$%^&*()<>?/\\|}{~:;[],.+-\\n'\n",
        "\n",
        "    for i in reversed(range(len(word))):\n",
        "        if word[i] not in tail_special:\n",
        "            break\n",
        "    try:\n",
        "      if i != len(word) - 1:\n",
        "          word = word[0: i + 1] + \" \" + word[i + 1:]\n",
        "    except:\n",
        "      print('ERROR word = {}'.format(word))\n",
        "      return word\n",
        "    if pos_head is True:\n",
        "        head_special = '@_!#$%^&*()<>?/\\|}{~:;[],.+-'\n",
        "\n",
        "        for i in range(len(word)):\n",
        "            if word[i] not in head_special:\n",
        "                break\n",
        "        \n",
        "        try:\n",
        "          if i != 0:\n",
        "              word = word[0: i] + \" \" + word[i:]\n",
        "        except:\n",
        "          print('ERROR word = {}'.format(word))\n",
        "         \n",
        "          return word\n",
        "    return word\n",
        "\n",
        "\n",
        "def replace_special_character(word: str):\n",
        "\n",
        "    characters = {'‚Ñ¢': '*', '‚Äò': \"'\", '¬Æ': 'x', '√ó': 'x', 'üòÄ': 'x', '‚Äë': '-',\n",
        "                  'ÃÅ': 'x', '‚Äî': ' - ', 'Ã£': 'x', '‚Äì': '-', '`': \"'\", '‚Äú': '\"', 'Ãâ': 'x',\n",
        "                  '‚Äô': \"'\", 'ÃÉ': 'x', '\\u200b': 'x', 'ÃÄ': 'x', '‚Äù': '\"', '‚Ä¶': '...',\n",
        "                  '\\ufeff': 'x', '‚Ä≥': '\"'}\n",
        "    try:\n",
        "      for c in characters:\n",
        "          if c in word:\n",
        "              word = word.replace(c, characters[c])\n",
        "    except:\n",
        "      print('ERROR word = {}'.format(word))\n",
        "      \n",
        "    return word\n",
        "\n",
        "\n",
        "def preprocess_sen(sentence: str) -> str:\n",
        "\n",
        "    # sentence = preprocess_stopword(sentence, list_stopwords)\n",
        "    words = sentence.split(' ')\n",
        "    norm_words = []\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        word = words[i]\n",
        "        word = unicodedata.normalize('NFC', word)\n",
        "\n",
        "        word = split_special_character(word)\n",
        "        word = replace_special_character(word)\n",
        "\n",
        "        norm_words.append(word)\n",
        "    \n",
        "    norm_text = \" \".join(norm_words)\n",
        "\n",
        "    return norm_text\n",
        "\n",
        "\n",
        "def split_sentence(text: str):\n",
        "\n",
        "    text = text.replace('\\r', '')\n",
        "    text = text.replace('\\n', '. ')\n",
        "    text += ' '\n",
        "\n",
        "    sentences = text.split('. ')\n",
        "    sentences = [sen.strip(' .') for sen in sentences]\n",
        "    sentences = [sen for sen in sentences if sen != '']\n",
        "    sentences = [sen + '.' for sen in sentences]\n",
        "\n",
        "    return sentences\n",
        "\n",
        "\n",
        "def preprocess_stopword(sentence: str, list_stopwords: list) -> str:\n",
        "\n",
        "    parts = []\n",
        "    special_char = '@_!#$%^&*()<>?/\\|}{~:;[],.+-'\n",
        "\n",
        "    for i in special_char:\n",
        "      sentence =  sentence.replace(i, ' ')\n",
        "\n",
        "    sentence = re.sub(' +',' ', sentence)\n",
        "    sent_segment = ViTokenizer.tokenize(sentence)\n",
        "    words = sent_segment.split()\n",
        "    \n",
        "    for word in words:\n",
        "      if \"_\" in word:\n",
        "        word_checking = \" \".join(word.split(\"_\"))\n",
        "      else:\n",
        "        word_checking = word\n",
        "\n",
        "      if word_checking.lower() not in list_stopwords:\n",
        "        parts.append(word)\n",
        "    \n",
        "    return \" \".join(parts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K14AnKPCL1vg"
      },
      "outputs": [],
      "source": [
        "dataset_test = pd.read_csv('/content/drive/MyDrive/Data/sentiment_analyst_data/DongDu_VN/test.csv')\n",
        "dataset_train = pd.read_csv('/content/drive/MyDrive/Data/sentiment_analyst_data/DongDu_VN/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "XZWinXYDoE9Z",
        "outputId": "7a3da02f-6af9-457a-fbf7-f7fb1c6b5653"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f95a8fb1-07d9-4b0f-91c3-112bb587e5f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>H√¥m_nay ƒëi ƒÉn t·∫°i qu√°n , m√≥n ƒÉn ngon v·ª´a_mi·ªáng...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Qua ÃÅ n c∆∞ Ã£ c ngon . Tu√¢ ÃÄ n na ÃÄ o mi ÃÄ nh c...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Ch√°n , ƒë·ªì u·ªëng kh√° nh·∫°t . V·ªõi kh√¥ng_gian v√† ch...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>M√¨ ƒÉn ok üëç üèª üëç üèª üëç üèª nh∆∞ng ngu·ªôi , view r·ªông ,...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>B·ªØa c√≥ gh√© ƒë√¢y ƒÉn , s√∫p ch·ªâ b√°n t√¥ , 1 t√¥ 15k ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57821</th>\n",
              "      <td>57821</td>\n",
              "      <td>Ch√¥ ÃÉ g∆∞ Ãâ i xe_h∆°i b√¢ ÃÅ t ti√™ Ã£ n ƒëi khoa Ãâ n...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57822</th>\n",
              "      <td>57822</td>\n",
              "      <td>Qu√°n n·∫±m trong ƒë∆∞·ªùng h∆°i kh√≥ t√¨m nh∆∞ng b√π l·∫°i ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57823</th>\n",
              "      <td>57823</td>\n",
              "      <td>M√¨nh d√πng deal khi t·ªõi ƒë√¢y nh∆∞ng nh√¢n_vi√™n v·∫´n...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57824</th>\n",
              "      <td>57824</td>\n",
              "      <td>Ph·∫ßn ƒÉn c·ªßa m√¨nh 2 ng∆∞·ªùi c√≥_th·ªÉ ƒÉn no . N√≥ g·ªìm...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57825</th>\n",
              "      <td>57825</td>\n",
              "      <td>ƒêi qua ƒë√¢y nhi·ªÅu l·∫ßn l·∫Øm m√† m√£i m·ªõi v√†o th·ª≠ . ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57826 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f95a8fb1-07d9-4b0f-91c3-112bb587e5f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f95a8fb1-07d9-4b0f-91c3-112bb587e5f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f95a8fb1-07d9-4b0f-91c3-112bb587e5f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0                                           sentence label\n",
              "0               0  H√¥m_nay ƒëi ƒÉn t·∫°i qu√°n , m√≥n ƒÉn ngon v·ª´a_mi·ªáng...   neg\n",
              "1               1  Qua ÃÅ n c∆∞ Ã£ c ngon . Tu√¢ ÃÄ n na ÃÄ o mi ÃÄ nh c...   neg\n",
              "2               2  Ch√°n , ƒë·ªì u·ªëng kh√° nh·∫°t . V·ªõi kh√¥ng_gian v√† ch...   neg\n",
              "3               3  M√¨ ƒÉn ok üëç üèª üëç üèª üëç üèª nh∆∞ng ngu·ªôi , view r·ªông ,...   neg\n",
              "4               4  B·ªØa c√≥ gh√© ƒë√¢y ƒÉn , s√∫p ch·ªâ b√°n t√¥ , 1 t√¥ 15k ...   neg\n",
              "...           ...                                                ...   ...\n",
              "57821       57821  Ch√¥ ÃÉ g∆∞ Ãâ i xe_h∆°i b√¢ ÃÅ t ti√™ Ã£ n ƒëi khoa Ãâ n...   pos\n",
              "57822       57822  Qu√°n n·∫±m trong ƒë∆∞·ªùng h∆°i kh√≥ t√¨m nh∆∞ng b√π l·∫°i ...   pos\n",
              "57823       57823  M√¨nh d√πng deal khi t·ªõi ƒë√¢y nh∆∞ng nh√¢n_vi√™n v·∫´n...   pos\n",
              "57824       57824  Ph·∫ßn ƒÉn c·ªßa m√¨nh 2 ng∆∞·ªùi c√≥_th·ªÉ ƒÉn no . N√≥ g·ªìm...   pos\n",
              "57825       57825  ƒêi qua ƒë√¢y nhi·ªÅu l·∫ßn l·∫Øm m√† m√£i m·ªõi v√†o th·ª≠ . ...   pos\n",
              "\n",
              "[57826 rows x 3 columns]"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyunenTXZ21J"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/NLP/Clean Data/vietnamese.txt'\n",
        "f = open(path, \"r\")\n",
        "list_stopwords  = [word[0:-1] for word in f.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLp4sUCyL1vj"
      },
      "outputs": [],
      "source": [
        "# dataset_train['tokens'] = dataset_train['tokens'].apply(lambda x: x[2:-2].split(\"', '\"))\n",
        "# dataset_train['tweet_cleaned'] = dataset_train['tokens'].apply(lambda x: \" \".join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT0v5gV2Il4c"
      },
      "outputs": [],
      "source": [
        "dataset_train['process_sent'] = dataset_train['sentence'].apply(lambda x: preprocess_sen(x))\n",
        "dataset_test['process_sent'] = dataset_test['sentence'].apply(lambda x: preprocess_sen(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQt1R2Vqhmnw"
      },
      "outputs": [],
      "source": [
        "dataset_train['label'] = dataset_train['label'].apply(lambda x: 1 if x == 'pos' else 0)\n",
        "dataset_test['label'] = dataset_test['label'].apply(lambda x: 1 if x == 'pos' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "G4PrdEMKmwCl",
        "outputId": "ef5e5cd5-cf59-4f9d-fb50-3076c1c0e8ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4b0be824-1297-45c4-9278-a2415927f971\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>process_sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>H√¥m_nay ƒëi ƒÉn t·∫°i qu√°n , m√≥n ƒÉn ngon v·ª´a_mi·ªáng...</td>\n",
              "      <td>0</td>\n",
              "      <td>H√¥m_nay ƒëi ƒÉn t·∫°i qu√°n , m√≥n ƒÉn ngon v·ª´a_mi·ªáng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Qua ÃÅ n c∆∞ Ã£ c ngon . Tu√¢ ÃÄ n na ÃÄ o mi ÃÄ nh c...</td>\n",
              "      <td>0</td>\n",
              "      <td>Qua x n c∆∞ x c ngon . Tu√¢ x n na x o mi x nh c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Ch√°n , ƒë·ªì u·ªëng kh√° nh·∫°t . V·ªõi kh√¥ng_gian v√† ch...</td>\n",
              "      <td>0</td>\n",
              "      <td>Ch√°n , ƒë·ªì u·ªëng kh√° nh·∫°t . V·ªõi kh√¥ng_gian v√† ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>M√¨ ƒÉn ok üëç üèª üëç üèª üëç üèª nh∆∞ng ngu·ªôi , view r·ªông ,...</td>\n",
              "      <td>0</td>\n",
              "      <td>M√¨ ƒÉn ok üëç üèª üëç üèª üëç üèª nh∆∞ng ngu·ªôi , view r·ªông ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>B·ªØa c√≥ gh√© ƒë√¢y ƒÉn , s√∫p ch·ªâ b√°n t√¥ , 1 t√¥ 15k ...</td>\n",
              "      <td>0</td>\n",
              "      <td>B·ªØa c√≥ gh√© ƒë√¢y ƒÉn , s√∫p ch·ªâ b√°n t√¥ , 1 t√¥ 15k ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57821</th>\n",
              "      <td>57821</td>\n",
              "      <td>Ch√¥ ÃÉ g∆∞ Ãâ i xe_h∆°i b√¢ ÃÅ t ti√™ Ã£ n ƒëi khoa Ãâ n...</td>\n",
              "      <td>1</td>\n",
              "      <td>Ch√¥ x g∆∞ x i xe_h∆°i b√¢ x t ti√™ x n ƒëi khoa x n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57822</th>\n",
              "      <td>57822</td>\n",
              "      <td>Qu√°n n·∫±m trong ƒë∆∞·ªùng h∆°i kh√≥ t√¨m nh∆∞ng b√π l·∫°i ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Qu√°n n·∫±m trong ƒë∆∞·ªùng h∆°i kh√≥ t√¨m nh∆∞ng b√π l·∫°i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57823</th>\n",
              "      <td>57823</td>\n",
              "      <td>M√¨nh d√πng deal khi t·ªõi ƒë√¢y nh∆∞ng nh√¢n_vi√™n v·∫´n...</td>\n",
              "      <td>1</td>\n",
              "      <td>M√¨nh d√πng deal khi t·ªõi ƒë√¢y nh∆∞ng nh√¢n_vi√™n v·∫´n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57824</th>\n",
              "      <td>57824</td>\n",
              "      <td>Ph·∫ßn ƒÉn c·ªßa m√¨nh 2 ng∆∞·ªùi c√≥_th·ªÉ ƒÉn no . N√≥ g·ªìm...</td>\n",
              "      <td>1</td>\n",
              "      <td>Ph·∫ßn ƒÉn c·ªßa m√¨nh 2 ng∆∞·ªùi c√≥_th·ªÉ ƒÉn no . N√≥ g·ªìm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57825</th>\n",
              "      <td>57825</td>\n",
              "      <td>ƒêi qua ƒë√¢y nhi·ªÅu l·∫ßn l·∫Øm m√† m√£i m·ªõi v√†o th·ª≠ . ...</td>\n",
              "      <td>1</td>\n",
              "      <td>ƒêi qua ƒë√¢y nhi·ªÅu l·∫ßn l·∫Øm m√† m√£i m·ªõi v√†o th·ª≠ . ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57826 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b0be824-1297-45c4-9278-a2415927f971')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b0be824-1297-45c4-9278-a2415927f971 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b0be824-1297-45c4-9278-a2415927f971');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0                                           sentence  label  \\\n",
              "0               0  H√¥m_nay ƒëi ƒÉn t·∫°i qu√°n , m√≥n ƒÉn ngon v·ª´a_mi·ªáng...      0   \n",
              "1               1  Qua ÃÅ n c∆∞ Ã£ c ngon . Tu√¢ ÃÄ n na ÃÄ o mi ÃÄ nh c...      0   \n",
              "2               2  Ch√°n , ƒë·ªì u·ªëng kh√° nh·∫°t . V·ªõi kh√¥ng_gian v√† ch...      0   \n",
              "3               3  M√¨ ƒÉn ok üëç üèª üëç üèª üëç üèª nh∆∞ng ngu·ªôi , view r·ªông ,...      0   \n",
              "4               4  B·ªØa c√≥ gh√© ƒë√¢y ƒÉn , s√∫p ch·ªâ b√°n t√¥ , 1 t√¥ 15k ...      0   \n",
              "...           ...                                                ...    ...   \n",
              "57821       57821  Ch√¥ ÃÉ g∆∞ Ãâ i xe_h∆°i b√¢ ÃÅ t ti√™ Ã£ n ƒëi khoa Ãâ n...      1   \n",
              "57822       57822  Qu√°n n·∫±m trong ƒë∆∞·ªùng h∆°i kh√≥ t√¨m nh∆∞ng b√π l·∫°i ...      1   \n",
              "57823       57823  M√¨nh d√πng deal khi t·ªõi ƒë√¢y nh∆∞ng nh√¢n_vi√™n v·∫´n...      1   \n",
              "57824       57824  Ph·∫ßn ƒÉn c·ªßa m√¨nh 2 ng∆∞·ªùi c√≥_th·ªÉ ƒÉn no . N√≥ g·ªìm...      1   \n",
              "57825       57825  ƒêi qua ƒë√¢y nhi·ªÅu l·∫ßn l·∫Øm m√† m√£i m·ªõi v√†o th·ª≠ . ...      1   \n",
              "\n",
              "                                            process_sent  \n",
              "0      H√¥m_nay ƒëi ƒÉn t·∫°i qu√°n , m√≥n ƒÉn ngon v·ª´a_mi·ªáng...  \n",
              "1      Qua x n c∆∞ x c ngon . Tu√¢ x n na x o mi x nh c...  \n",
              "2      Ch√°n , ƒë·ªì u·ªëng kh√° nh·∫°t . V·ªõi kh√¥ng_gian v√† ch...  \n",
              "3      M√¨ ƒÉn ok üëç üèª üëç üèª üëç üèª nh∆∞ng ngu·ªôi , view r·ªông ,...  \n",
              "4      B·ªØa c√≥ gh√© ƒë√¢y ƒÉn , s√∫p ch·ªâ b√°n t√¥ , 1 t√¥ 15k ...  \n",
              "...                                                  ...  \n",
              "57821  Ch√¥ x g∆∞ x i xe_h∆°i b√¢ x t ti√™ x n ƒëi khoa x n...  \n",
              "57822  Qu√°n n·∫±m trong ƒë∆∞·ªùng h∆°i kh√≥ t√¨m nh∆∞ng b√π l·∫°i ...  \n",
              "57823  M√¨nh d√πng deal khi t·ªõi ƒë√¢y nh∆∞ng nh√¢n_vi√™n v·∫´n...  \n",
              "57824  Ph·∫ßn ƒÉn c·ªßa m√¨nh 2 ng∆∞·ªùi c√≥_th·ªÉ ƒÉn no . N√≥ g·ªìm...  \n",
              "57825  ƒêi qua ƒë√¢y nhi·ªÅu l·∫ßn l·∫Øm m√† m√£i m·ªõi v√†o th·ª≠ . ...  \n",
              "\n",
              "[57826 rows x 4 columns]"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "L_lcIWnvmySG",
        "outputId": "08173ae2-244f-472a-cd92-ce8e6060464d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7b185935-c20f-4995-9762-4716f5abb580\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>process_sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>C≈©ng ch·∫£ c√≥ g√¨ ƒë·∫∑c_bi·ªát , ch·ªâ ƒë∆∞·ª£ c√°i r·∫ª th√¥i ...</td>\n",
              "      <td>0</td>\n",
              "      <td>C≈©ng ch·∫£ c√≥ g√¨ ƒë·∫∑c_bi·ªát , ch·ªâ ƒë∆∞·ª£ c√°i r·∫ª th√¥i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>V·ªõi_l·∫°i ch·ªó n√†y kh√¥ng_gian qu√° h·∫πp , m√† thi·ªát ...</td>\n",
              "      <td>0</td>\n",
              "      <td>V·ªõi_l·∫°i ch·ªó n√†y kh√¥ng_gian qu√° h·∫πp , m√† thi·ªát ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>B√°nh flan truy·ªÅn_th·ªëng ƒÉn ƒë∆∞·ª£c nh·∫•t . Socola v...</td>\n",
              "      <td>0</td>\n",
              "      <td>B√°nh flan truy·ªÅn_th·ªëng ƒÉn ƒë∆∞·ª£c nh·∫•t . Socola v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>V·ªÅ h√° c·∫£o v√† x√≠u_m·∫°i th√¨ c≈©ng b√¨nh_th∆∞·ªùng , kh...</td>\n",
              "      <td>0</td>\n",
              "      <td>V·ªÅ h√° c·∫£o v√† x√≠u_m·∫°i th√¨ c≈©ng b√¨nh_th∆∞·ªùng , kh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Ch·∫Øc l√† gi√° b√¨nh_d√¢n n√™n c≈©ng kh√¥ng ƒë√≤i_h·ªèi ƒë∆∞...</td>\n",
              "      <td>0</td>\n",
              "      <td>Ch·∫Øc l√† gi√° b√¨nh_d√¢n n√™n c≈©ng kh√¥ng ƒë√≤i_h·ªèi ƒë∆∞...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23163</th>\n",
              "      <td>23163</td>\n",
              "      <td>M·ª≥ v√† c∆°m ·ªü ƒë√¢y r·∫•t ngon ƒë·∫∑c_bi·ªát l√† m·∫•y lo·∫°i ...</td>\n",
              "      <td>1</td>\n",
              "      <td>M·ª≥ v√† c∆°m ·ªü ƒë√¢y r·∫•t ngon ƒë·∫∑c_bi·ªát l√† m·∫•y lo·∫°i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23164</th>\n",
              "      <td>23164</td>\n",
              "      <td>C∆°m c·ª±c_k√¨ ngon nh√© th·ªãt r·∫•t nh√¨u tr·ªôn ƒë·ªÅu v√† ...</td>\n",
              "      <td>1</td>\n",
              "      <td>C∆°m c·ª±c_k√¨ ngon nh√© th·ªãt r·∫•t nh√¨u tr·ªôn ƒë·ªÅu v√† ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23165</th>\n",
              "      <td>23165</td>\n",
              "      <td>B√°nh tr√¥ng ƒë·∫πp nhg ƒÉn hk ngon l·∫Øm v√† gi√° kh√° m...</td>\n",
              "      <td>1</td>\n",
              "      <td>B√°nh tr√¥ng ƒë·∫πp nhg ƒÉn hk ngon l·∫Øm v√† gi√° kh√° m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23166</th>\n",
              "      <td>23166</td>\n",
              "      <td>Nc u·ªëng ·ªü ƒë√¢y n·∫øu b·∫°n hk g·ªçi s·∫Ω c√≥ tr√† ƒë√° free...</td>\n",
              "      <td>1</td>\n",
              "      <td>Nc u·ªëng ·ªü ƒë√¢y n·∫øu b·∫°n hk g·ªçi s·∫Ω c√≥ tr√† ƒë√° free...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23167</th>\n",
              "      <td>23167</td>\n",
              "      <td>Kh√¥ng_gian ·∫•m_c√∫ng , gi√° c≈©ng kh√° cao , nh√¢n_v...</td>\n",
              "      <td>1</td>\n",
              "      <td>Kh√¥ng_gian ·∫•m_c√∫ng , gi√° c≈©ng kh√° cao , nh√¢n_v...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23168 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b185935-c20f-4995-9762-4716f5abb580')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b185935-c20f-4995-9762-4716f5abb580 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b185935-c20f-4995-9762-4716f5abb580');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0                                           sentence  label  \\\n",
              "0               0  C≈©ng ch·∫£ c√≥ g√¨ ƒë·∫∑c_bi·ªát , ch·ªâ ƒë∆∞·ª£ c√°i r·∫ª th√¥i ...      0   \n",
              "1               1  V·ªõi_l·∫°i ch·ªó n√†y kh√¥ng_gian qu√° h·∫πp , m√† thi·ªát ...      0   \n",
              "2               2  B√°nh flan truy·ªÅn_th·ªëng ƒÉn ƒë∆∞·ª£c nh·∫•t . Socola v...      0   \n",
              "3               3  V·ªÅ h√° c·∫£o v√† x√≠u_m·∫°i th√¨ c≈©ng b√¨nh_th∆∞·ªùng , kh...      0   \n",
              "4               4  Ch·∫Øc l√† gi√° b√¨nh_d√¢n n√™n c≈©ng kh√¥ng ƒë√≤i_h·ªèi ƒë∆∞...      0   \n",
              "...           ...                                                ...    ...   \n",
              "23163       23163  M·ª≥ v√† c∆°m ·ªü ƒë√¢y r·∫•t ngon ƒë·∫∑c_bi·ªát l√† m·∫•y lo·∫°i ...      1   \n",
              "23164       23164  C∆°m c·ª±c_k√¨ ngon nh√© th·ªãt r·∫•t nh√¨u tr·ªôn ƒë·ªÅu v√† ...      1   \n",
              "23165       23165  B√°nh tr√¥ng ƒë·∫πp nhg ƒÉn hk ngon l·∫Øm v√† gi√° kh√° m...      1   \n",
              "23166       23166  Nc u·ªëng ·ªü ƒë√¢y n·∫øu b·∫°n hk g·ªçi s·∫Ω c√≥ tr√† ƒë√° free...      1   \n",
              "23167       23167  Kh√¥ng_gian ·∫•m_c√∫ng , gi√° c≈©ng kh√° cao , nh√¢n_v...      1   \n",
              "\n",
              "                                            process_sent  \n",
              "0      C≈©ng ch·∫£ c√≥ g√¨ ƒë·∫∑c_bi·ªát , ch·ªâ ƒë∆∞·ª£ c√°i r·∫ª th√¥i ...  \n",
              "1      V·ªõi_l·∫°i ch·ªó n√†y kh√¥ng_gian qu√° h·∫πp , m√† thi·ªát ...  \n",
              "2      B√°nh flan truy·ªÅn_th·ªëng ƒÉn ƒë∆∞·ª£c nh·∫•t . Socola v...  \n",
              "3      V·ªÅ h√° c·∫£o v√† x√≠u_m·∫°i th√¨ c≈©ng b√¨nh_th∆∞·ªùng , kh...  \n",
              "4      Ch·∫Øc l√† gi√° b√¨nh_d√¢n n√™n c≈©ng kh√¥ng ƒë√≤i_h·ªèi ƒë∆∞...  \n",
              "...                                                  ...  \n",
              "23163  M·ª≥ v√† c∆°m ·ªü ƒë√¢y r·∫•t ngon ƒë·∫∑c_bi·ªát l√† m·∫•y lo·∫°i ...  \n",
              "23164  C∆°m c·ª±c_k√¨ ngon nh√© th·ªãt r·∫•t nh√¨u tr·ªôn ƒë·ªÅu v√† ...  \n",
              "23165  B√°nh tr√¥ng ƒë·∫πp nhg ƒÉn hk ngon l·∫Øm v√† gi√° kh√° m...  \n",
              "23166  Nc u·ªëng ·ªü ƒë√¢y n·∫øu b·∫°n hk g·ªçi s·∫Ω c√≥ tr√† ƒë√° free...  \n",
              "23167  Kh√¥ng_gian ·∫•m_c√∫ng , gi√° c≈©ng kh√° cao , nh√¢n_v...  \n",
              "\n",
              "[23168 rows x 4 columns]"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK0yuPlTg7hv",
        "outputId": "270bc89c-e154-4aed-9924-f97fb4a4b2e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwbnFOSIbAK9"
      },
      "outputs": [],
      "source": [
        "dataset_train['token'] = dataset_train['process_sent'].apply(lambda x: word_tokenize(x))\n",
        "dataset_test['token'] = dataset_test['process_sent'].apply(lambda x: word_tokenize(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGS_LaFhj9f3"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUvza7XoqXHo",
        "outputId": "0546e2eb-0a81-4b0c-d32f-61bf48fa5a6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80994/80994 [00:01<00:00, 52725.05it/s]\n"
          ]
        }
      ],
      "source": [
        "datasets = dataset_train.append(dataset_test)\n",
        "sequences_token = datasets['token'].values.tolist()\n",
        "vocab = Counter()\n",
        "for tokens in tqdm(sequences_token):\n",
        "    vocab.update(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSiyTqCXqyWF",
        "outputId": "ed98ee73-7e83-4292-937e-aee7637f41f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50110"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l6fBy6Oh0Yv"
      },
      "outputs": [],
      "source": [
        "def get_datasets(df, max_lenght, vocabsize = 30000):\n",
        "  \n",
        "\n",
        "  sequences_text = df['process_sent'].values.tolist()\n",
        "  sequences_token = df['token'].values.tolist()\n",
        "  y_target = np.array(df['label'].values.tolist())\n",
        "\n",
        " \n",
        "  onehot_repr=[one_hot(words,vocabsize)for words in sequences_text]\n",
        "  embedded_docs=pad_sequences(onehot_repr,padding='post',maxlen=max_lenght)\n",
        "\n",
        "  X =np.array(embedded_docs)\n",
        "  return X, y_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XQesFdPL1vj"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = get_datasets(dataset_train, max_lenght = 70)\n",
        "x_test, y_test = get_datasets(dataset_test, max_lenght = 70)\n",
        "# y_train = to_categorical(targets, num_classes = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6T2PX7OL1vj"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smx6RLIWEXRZ"
      },
      "source": [
        "### Word2Vec: Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNmKa2tOL1vk"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sequences_token, window=5, min_count=5, workers=16, sg=0, negative=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHlWFvT_L1vk",
        "outputId": "f5de8ab3-31e9-4ff5-ebe3-e941c3e7c464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of word vectors: 5688\n"
          ]
        }
      ],
      "source": [
        "word_vectors = model.wv\n",
        "print(\"Number of word vectors: {}\".format(len(word_vectors.vocab)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP8pq-plVqQ9",
        "outputId": "e57a30b4-15aa-4246-a49b-7a9abfc93fd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7f82c4ae7c90>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_index = {t[0]: i+1 for i,t in enumerate(vocab.most_common(NUM_VOCAB))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgGUgcAiaLif"
      },
      "outputs": [],
      "source": [
        "# add 'UNK' -> unknow, 'PAD -> Padding in word indexx\n",
        "word_index['UNK'] = 0\n",
        "word_index['PAD'] = max(word_index.values()) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhG43nXQL1vl"
      },
      "outputs": [],
      "source": [
        "sequences = [[word_index.get(t, word_index['UNK']) for t in token]\n",
        "             for token in sequences_token]\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\", value= word_index['PAD'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es7msvPaL1vm"
      },
      "outputs": [],
      "source": [
        "data[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_fKQK0AB2SG",
        "outputId": "d2b09294-d880-4d38-b0fc-cd0007544ab6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bihday', 'majesty']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences_token[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGizoWdxL1vm"
      },
      "outputs": [],
      "source": [
        "# bulding word matrix: dimension of matrix = number most fequency words's vocab -> word not in most word's vocab will random value\n",
        "\n",
        "# we initialize the matrix with random numbers\n",
        "wv_matrix = (np.random.rand(len(word_index), WV_DIM) - 0.5) / 5.0\n",
        "for word, i in word_index.items():\n",
        "\n",
        "    try:\n",
        "        embedding_vector = word_vectors[word]\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        wv_matrix[i] = embedding_vector\n",
        "    except:\n",
        "        pass  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQF6Cf3iFQZ7"
      },
      "source": [
        "## Embedding: Onehot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuUX6IR8FVrs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ncENKBPKJrF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Y_lstm = to_categorical(targets, num_classes = 2)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_lstm, np.array(targets), test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOWZuWPmC3mW"
      },
      "source": [
        "### Model Neural netword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRxCah_VL1vm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, LSTM,Bidirectional, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnJqFVmdRJPu"
      },
      "outputs": [],
      "source": [
        "vocabsize = 30000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xy3eUOETL1vp"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "# model.add(Embedding(input_dim = len(word_index), output_dim = 100, embeddings_initializer = tensorflow.keras.initializers.Constant(wv_matrix), input_length= MAX_SEQUENCE_LENGTH))\n",
        "model.add(Embedding(input_dim = vocabsize,output_dim = 50, input_length= MAX_SEQUENCE_LENGTH))\n",
        "\n",
        "model.add(Bidirectional(LSTM(100,return_sequences=False)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# model.add(LSTM(20,return_sequences=False))\n",
        "# model.add(Dropout(0.3)) \n",
        "\n",
        "model.add(Dense(1, activation ='sigmoid'))\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer= Adam(learning_rate=1e-2), metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIeghVmBOvpF",
        "outputId": "7b45f4d0-fb82-4535-b6f7-5928a1e9f43d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "58/58 [==============================] - 141s 2s/step - loss: 0.5713 - acc: 0.7221 - val_loss: 0.5288 - val_acc: 0.7564\n",
            "Epoch 2/10\n",
            "58/58 [==============================] - 114s 2s/step - loss: 0.3999 - acc: 0.8227 - val_loss: 0.4423 - val_acc: 0.7926\n",
            "Epoch 3/10\n",
            "58/58 [==============================] - 101s 2s/step - loss: 0.3531 - acc: 0.8480 - val_loss: 0.4447 - val_acc: 0.7930\n",
            "Epoch 4/10\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.3201 - acc: 0.8627 - val_loss: 0.4606 - val_acc: 0.7958\n",
            "Epoch 5/10\n",
            "58/58 [==============================] - 96s 2s/step - loss: 0.2814 - acc: 0.8822 - val_loss: 0.4739 - val_acc: 0.7954\n",
            "Epoch 6/10\n",
            "58/58 [==============================] - 96s 2s/step - loss: 0.2550 - acc: 0.8925 - val_loss: 0.5296 - val_acc: 0.7905\n",
            "Epoch 7/10\n",
            "58/58 [==============================] - 96s 2s/step - loss: 0.2307 - acc: 0.9034 - val_loss: 0.5369 - val_acc: 0.7871\n",
            "Epoch 8/10\n",
            "58/58 [==============================] - 97s 2s/step - loss: 0.2043 - acc: 0.9142 - val_loss: 0.6053 - val_acc: 0.7815\n",
            "Epoch 9/10\n",
            "58/58 [==============================] - 96s 2s/step - loss: 0.1869 - acc: 0.9223 - val_loss: 0.6813 - val_acc: 0.7849\n",
            "Epoch 10/10\n",
            "58/58 [==============================] - 100s 2s/step - loss: 0.1715 - acc: 0.9296 - val_loss: 0.6764 - val_acc: 0.7838\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d82938d10>"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10,batch_size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAOk-vbOwzpU"
      },
      "outputs": [],
      "source": [
        "sequences_text = ['Anh s·ªõm v·ªÅ v·ªõi em :(((((']\n",
        "onehot_repr=[one_hot(words,vocabsize)for words in sequences_text]\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='post',maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "X =np.array(embedded_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRJzwm_ow8IG",
        "outputId": "2e9a1380-120f-4823-af36-cd8a456dd4f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day la mot cau t√≠ch c·ª±c\n"
          ]
        }
      ],
      "source": [
        "value = model.predict(X)[0]\n",
        "if value > 0.5:\n",
        "  print('day la mot cau t√≠ch c·ª±c')\n",
        "else:\n",
        "  print('c√¢u ti√™u c·ª±c')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5-c2DcALuil",
        "outputId": "67878a39-9cf7-4e35-8d12-1ce4e48f4e10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/model/my_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/model/my_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0d82d47b90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0d850ea6d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/NLP/model/my_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWc12TQvM52Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjpoOP5YMpbw",
        "outputId": "98c44370-47df-4c71-a964-e5fc7a2274ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score:  0.7837966160220995\n",
            "Confusion Matrix: \n",
            " [[8219 3253]\n",
            " [1756 9940]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.72      0.77     11472\n",
            "           1       0.75      0.85      0.80     11696\n",
            "\n",
            "    accuracy                           0.78     23168\n",
            "   macro avg       0.79      0.78      0.78     23168\n",
            "weighted avg       0.79      0.78      0.78     23168\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_lstm=model.predict(x_test)\n",
        "y_pred_lstm = np.round(abs(y_pred_lstm))\n",
        "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred_lstm))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test,y_pred_lstm))\n",
        "print(classification_report(y_test,y_pred_lstm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OxMKMKML1vq"
      },
      "outputs": [],
      "source": [
        "! pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wNi_kEIL1vr"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gMeQJEHL1vs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import common_texts\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3C2iZIzL1vs"
      },
      "outputs": [],
      "source": [
        "# train word2vec on the two sentences\n",
        "model = KeyedVectors.load_word2vec_format('/Users/phamvanmanh/Desktop/learn_python/tokenizer/gensim/wiki-news-300d-1M.vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKUUXuwFL1vs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjpeRK-_L1vt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(sentences_vectonizer,targets,test_size=0.2,random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjpAib3OL1vt"
      },
      "source": [
        "### Logistic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k0WEY7nL1vt"
      },
      "outputs": [],
      "source": [
        "df_results = pd.DataFrame(data=np.zeros(shape=(1,3)), columns = ['classifier', 'train_score', 'test_score'] )\n",
        "train_score = clf.score(x_train, y_train)\n",
        "test_score = clf.score(x_test, y_test)\n",
        "\n",
        "df_results.loc[0,'classifier'] = \"MLP\"\n",
        "df_results.loc[0,'train_score'] = train_score\n",
        "df_results.loc[0,'test_score'] = test_score\n",
        " \n",
        "print(df_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJOvXpkRL1vu"
      },
      "outputs": [],
      "source": [
        "### Neuron Network\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6hlZzzBL1vu"
      },
      "outputs": [],
      "source": [
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
        "clf.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj_0g6wNL1vv"
      },
      "outputs": [],
      "source": [
        "df_results = pd.DataFrame(data=np.zeros(shape=(1,3)), columns = ['classifier', 'train_score', 'test_score'] )\n",
        "train_score = clf.score(x_train, y_train)\n",
        "test_score = clf.score(x_test, y_test)\n",
        " \n",
        " \n",
        "df_results.loc[1,'classifier'] = \"MLP\"\n",
        "df_results.loc[1,'train_score'] = train_score\n",
        "df_results.loc[1,'test_score'] = test_score\n",
        " \n",
        "print(df_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hhyn3YkTL1vv"
      },
      "outputs": [],
      "source": [
        "sum(clf.predict(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH46JehZL1vv"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1YG24MgL1vv"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X, y = load_iris(return_X_y=True)\n",
        "# clf = LogisticRegression(random_state=0).fit(X, y)\n",
        "# clf.predict(X[:2, :])\n",
        "# array([0, 0])\n",
        "# clf.predict_proba(X[:2, :])\n",
        "# array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
        "#        [9.7...e-01, 2.8...e-02, ...e-08]])\n",
        "# clf.score(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQjCh_MaL1vw"
      },
      "outputs": [],
      "source": [
        "sentences = [['this', 'is', 'the', 'good', 'machine', 'learning', 'book'],\n",
        "            ['this', 'is',  'another', 'machine', 'learning', 'book'],\n",
        "            ['one', 'more', 'new', 'book'],\n",
        "         \n",
        "          ['this', 'is', 'about', 'machine', 'learning', 'post'],\n",
        "          ['orange', 'juice', 'is', 'the', 'liquid', 'extract', 'of', 'fruit'],\n",
        "          ['orange', 'juice', 'comes', 'in', 'several', 'different', 'varieties'],\n",
        "          ['this', 'is', 'the', 'last', 'machine', 'learning', 'book'],\n",
        "          ['orange', 'juice', 'comes', 'in', 'several', 'different', 'packages'],\n",
        "          ['orange', 'juice', 'is', 'liquid', 'extract', 'from', 'fruit', 'on', 'orange', 'tree']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "0dxjcdykL1vw",
        "outputId": "f23ef6bf-6755-4105-8ad2-8966de647fe2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c8edde6e04dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sent_vectorizer' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        " \n",
        "\n",
        " \n",
        " \n",
        "V=[]\n",
        "for sentence in sentences:\n",
        "    V.append(sent_vectorizer(sentence, model)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6-pywNGL1vw"
      },
      "outputs": [],
      "source": [
        "V[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1wNi_kEIL1vr",
        "RjpAib3OL1vt",
        "PH46JehZL1vv"
      ],
      "name": "sentiment_analyst.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "68143ed56c1ce766ae279abd81de569bc5c26c46c2fac394614c54ae0a159bde"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('akb_env': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
